{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aofNbODMK2M"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 8)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.10 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.10\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Fetching and Processing**"
      ],
      "metadata": {
        "id": "D7Bkx_2lSw0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get CIFAR100 data from Keras datasets\n",
        "# In this task, targets are irrelevant. Therefore we just keep the 32*32 RGB images\n",
        "\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "(x_trainC, _), (x_testC, _) = cifar100.load_data()"
      ],
      "metadata": {
        "id": "TIvw26QtSnVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize images\n",
        "\n",
        "x_trainC = x_trainC.astype('float32') / 255.\n",
        "x_testC = x_testC.astype('float32') / 255.\n",
        "\n",
        "print(x_trainC.shape)\n",
        "print(x_testC.shape)"
      ],
      "metadata": {
        "id": "R4qiQ-QqTHKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add noise to images.\n",
        "# The parameter noise_factor defines the strength of the perturbation\n",
        "# https://www.tensorflow.org/api_docs/python/tf/random/normal\n",
        "\n",
        "# After the noise perturbation, the values still belong to the interval [0, 1]\n",
        "\n",
        "noise_factor = 0.1\n",
        "x_trainC_noisy = x_trainC + noise_factor * tf.random.normal(shape=x_trainC.shape)\n",
        "x_testC_noisy = x_testC + noise_factor * tf.random.normal(shape=x_testC.shape)\n",
        "\n",
        "x_trainC_noisy = tf.clip_by_value(x_trainC_noisy, clip_value_min=0., clip_value_max=1.)\n",
        "x_testC_noisy = tf.clip_by_value(x_testC_noisy, clip_value_min=0., clip_value_max=1.)"
      ],
      "metadata": {
        "id": "9ya1phMxTO_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few images before and after the perturbation\n",
        "# Change the value of start to inspect other images\n",
        "\n",
        "start= 10\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(tf.squeeze(x_testC[i+start]))\n",
        "    plt.gray()\n",
        "\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"Noisy\")\n",
        "    plt.imshow(tf.squeeze(x_testC_noisy[i+start]))\n",
        "    plt.gray()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XAFBvdKYTPBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of the Denoising AutoEncoder**"
      ],
      "metadata": {
        "id": "quGWXSy9UdQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoise is a subclass of the generic Model class\n",
        "# Complete the Decoder section. You should use Conv2DTranspose layers to reconstruct (upsample) the latent representation to the original image dimensions\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\n",
        "# https://keras.io/api/models/model/#model-class\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class DenoiseC(Model):\n",
        "  def __init__(self):\n",
        "    super(DenoiseC, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(32, 32, 3)),\n",
        "      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(8, (3,3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2DTranspose(16, (3,3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(3, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "eZOvR1gBTPD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Autoencoder object\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "autoencoderC = DenoiseC()"
      ],
      "metadata": {
        "id": "aOPIzsJxT4L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile and Train**"
      ],
      "metadata": {
        "id": "aajnxGoCUgfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "# This is a regression problem, where the loss corresponds to the difference between the input (noisy image) and the output (original image)\n",
        "# Therefore, the Autoencoder must remove the noise from the input , aiming at delivering a clear image\n",
        "\n",
        "autoencoderC.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())\n",
        "\n",
        "autoencoderC.fit(x_trainC_noisy, x_trainC,\n",
        "                epochs=10,\n",
        "                shuffle=True)"
      ],
      "metadata": {
        "id": "TnDg_JTmT4PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the reduction of dimension from the original image to the latent representation (Encoder)\n",
        "# Confirm the expansion from the latent representation to the original dimension (Decoder)\n",
        "\n",
        "autoencoderC.summary()\n",
        "\n",
        "print('***Encoder***')\n",
        "autoencoderC.encoder.summary()\n",
        "\n",
        "print('***Decoder***')\n",
        "autoencoderC.decoder.summary()\n"
      ],
      "metadata": {
        "id": "kvlBlB6jURJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Performance**"
      ],
      "metadata": {
        "id": "HxjYE4TnUn4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance on the test set\n",
        "\n",
        "autoencoderC.evaluate(x_testC_noisy, x_testC)"
      ],
      "metadata": {
        "id": "8pyBmnVNURLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply trained autoencoder to images from the test set\n",
        "\n",
        "encoded_imgs = autoencoderC.encoder(x_testC_noisy).numpy()\n",
        "decoded_imgs = autoencoderC.decoder(encoded_imgs).numpy()"
      ],
      "metadata": {
        "id": "toVipXd6TPHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize all transformations\n",
        "# 1. Original images\n",
        "# 2. Noise images\n",
        "# 3. Denoised images\n",
        "\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(n):\n",
        "\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(tf.squeeze(x_testC[i+start]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display original + noise\n",
        "    ax = plt.subplot(3, n, i + n + 1)\n",
        "    plt.title(\"Noisy\")\n",
        "    plt.imshow(tf.squeeze(x_testC_noisy[i+start]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    bx = plt.subplot(3, n, i + n*2 + 1)\n",
        "    plt.title(\"Denoised\")\n",
        "    plt.imshow(tf.squeeze(decoded_imgs[i+start]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CvMljq6LUyOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}