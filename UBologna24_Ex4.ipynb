{
  "cells": [
{
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoBPereira/DeepLearning-UBologna/blob/main/UBologna24_Ex4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aofNbODMK2M"
      },
      "outputs": [],
      "source": [
        "# Setup, Version check and Common imports\n",
        "\n",
        "# Python ≥3.8 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 8)\n",
        "\n",
        "\n",
        "# TensorFlow ≥2.10 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.10\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaCLRr_uM1iT"
      },
      "outputs": [],
      "source": [
        "# Load CIFAR10 dataset from keras datasets:\n",
        "# https://keras.io/api/datasets/cifar10/\n",
        "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "# This is a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories.\n",
        "\n",
        "# The load_data() method creates train and test sets.\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(train_images_full, train_labels_full), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_labels_full = train_labels_full.squeeze()\n",
        "test_labels = test_labels.squeeze()\n",
        "\n",
        "# Images are not standardized. They will be preprocessed by the model\n",
        "\n",
        "# We further divide the original train datasets into train and validation datasets\n",
        "train_images = train_images_full[5000:]\n",
        "valid_images = train_images_full[:5000]\n",
        "train_labels = train_labels_full[5000:]\n",
        "valid_labels = train_labels_full[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vFkzwgUy1tK"
      },
      "outputs": [],
      "source": [
        "# Obtain the pretrained Xception Model from keras applications: https://keras.io/api/applications/\n",
        "# It does not include the classification section (include_top = False) and weights are frozen\n",
        "\n",
        "base_model = keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "\n",
        "base_model.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_HhmhXUPq0X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# The complete model: It comprises the Xception model and the classification layers\n",
        "# The Global Average Pooling layer is used to linearize information\n",
        "\n",
        "# In this example, the Keras functional API is used\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "x = layers.Lambda(lambda image: tf.image.resize(image, (224,224)))(inputs)\n",
        "x = tf.keras.applications.xception.preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(10, activation=('softmax'))(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bBxU4cFP4xO"
      },
      "outputs": [],
      "source": [
        "# Present a summary of the network architecture\n",
        "# Confirm the architecture and the number of parameters\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgU59bL4QGsZ"
      },
      "outputs": [],
      "source": [
        "# A NN has to be compiled by calling the compile() method: https://keras.io/api/models/model_training_apis/\n",
        "# Three components have to be defined (recall how backpropagation is appplied during training):\n",
        "# 1. the Optimizer to be used in training\n",
        "# 2. The loss function\n",
        "# 3. The evaluation metric\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU4IE-yfQMsF"
      },
      "outputs": [],
      "source": [
        "# Training is performed by calling the fit() method: https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "# Hyper-parameters: batch size and epochs\n",
        "# Validation datasets can also be provided\n",
        "\n",
        "# It returns a history object.\n",
        "# Its History.history attribute is a record of training loss values and metrics values at successive epochs,\n",
        "# as well as validation loss values and validation metrics values (if applicable).\n",
        "\n",
        "# Only 5 epochs are performed, as training will take a long time\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=5,\n",
        "                    validation_data=(valid_images, valid_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqxE-GIHSwqt"
      },
      "outputs": [],
      "source": [
        "# Plot the evolution of the accuracy metrics\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "x = pd.DataFrame(history.history, columns = ['accuracy', 'val_accuracy'])\n",
        "x.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alJ-O4pxS1u8"
      },
      "outputs": [],
      "source": [
        "# Evaluation the generalization ability of the model\n",
        "# The test set will be used in this step\n",
        "# Classification of a set of examples can be performed using the evaluate() method:  https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test Accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLVkfdPRMCfe"
      },
      "outputs": [],
      "source": [
        "dot_img_file = '/tmp/model_3.png'\n",
        "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
